{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#definition of the yaw cases\n",
    "\n",
    "yaw_cases = {\n",
    "    \"0deg_baseline_csv\": 0.0,\n",
    "    \"15deg_baseline_csv\": 15.0,\n",
    "    \"30deg_baseline_csv\": 30.0,\n",
    "    \"45deg_baseline_csv\": 45.0,\n",
    "}\n",
    "import os \n",
    "import numpy as np \n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_field_csv(path, expected_components, field_name):\n",
    "    \"\"\"\n",
    "    Read a CSV file for a scalar or vector field and return a numeric numpy array.\n",
    "\n",
    "    expected_components = 1 for scalar (p, k, nut, omega)\n",
    "                        = 3 for vector (U)\n",
    "    \"\"\"\n",
    "    # 1) Read with header row\n",
    "    df = pd.read_csv(path, header=0)   # first line is header: 'cellId,Ux,Uy,Uz' etc.\n",
    "\n",
    "    # 2) Convert all columns to numeric, coercing bad values to NaN\n",
    "    for col in df.columns:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "    # 3) Drop columns that are completely NaN (purely non-numeric or empty)\n",
    "    df = df.dropna(axis=1, how='all')\n",
    "\n",
    "    # 4) Drop rows that are completely NaN (e.g., blank lines at end)\n",
    "    df = df.dropna(axis=0, how='all')\n",
    "\n",
    "    # 5) Now we should only have numeric columns.\n",
    "    #    If there are extra columns (e.g., 'cellId'), keep only the last expected_components.\n",
    "    if df.shape[1] > expected_components:\n",
    "        df = df.iloc[:, -expected_components:]\n",
    "\n",
    "    # 6) If there are fewer columns, that’s a real problem.\n",
    "    if df.shape[1] != expected_components:\n",
    "        raise ValueError(\n",
    "            f\"{field_name}: expected {expected_components} numeric columns, \"\n",
    "            f\"but got {df.shape[1]} in file {path}. \"\n",
    "            f\"Columns seen: {list(df.columns)}\"\n",
    "        )\n",
    "\n",
    "    return df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_snapshot(folder_path, n_cells_ref=None):\n",
    "    \"\"\"Load one timestep folder: U, p, k, nut, omega; flatten into 1D vector.\"\"\"\n",
    "\n",
    "    U = read_field_csv(\n",
    "        os.path.join(folder_path, \"U.csv\"),\n",
    "        expected_components=3,\n",
    "        field_name=\"U\"\n",
    "    )  # shape: (N, 3)\n",
    "\n",
    "    p = read_field_csv(\n",
    "        os.path.join(folder_path, \"p.csv\"),\n",
    "        expected_components=1,\n",
    "        field_name=\"p\"\n",
    "    )  # shape: (N, 1)\n",
    "\n",
    "    k = read_field_csv(\n",
    "        os.path.join(folder_path, \"k.csv\"),\n",
    "        expected_components=1,\n",
    "        field_name=\"k\"\n",
    "    )\n",
    "\n",
    "    nut = read_field_csv(\n",
    "        os.path.join(folder_path, \"nut.csv\"),\n",
    "        expected_components=1,\n",
    "        field_name=\"nut\"\n",
    "    )\n",
    "\n",
    "    omega = read_field_csv(\n",
    "        os.path.join(folder_path, \"omega.csv\"),\n",
    "        expected_components=1,\n",
    "        field_name=\"omega\"\n",
    "    )\n",
    "\n",
    "    # Consistency check: same number of cells in all fields\n",
    "    N = U.shape[0]\n",
    "    for arr, name in [(p, \"p\"), (k, \"k\"), (nut, \"nut\"), (omega, \"omega\")]:\n",
    "        if arr.shape[0] != N:\n",
    "            raise ValueError(\n",
    "                f\"Cell count mismatch in {folder_path}: \"\n",
    "                f\"U has {N} rows but {name} has {arr.shape[0]} rows\"\n",
    "            )\n",
    "\n",
    "    # Optional: check against reference cell count from the first snapshot\n",
    "    if n_cells_ref is not None and N != n_cells_ref:\n",
    "        raise ValueError(\n",
    "            f\"Inconsistent cell count in {folder_path}: \"\n",
    "            f\"expected {n_cells_ref}, but got {N}\"\n",
    "        )\n",
    "\n",
    "    # Concatenate along feature dimension and flatten\n",
    "    fields = np.hstack([U, p, k, nut, omega])  # shape: (N, 7)\n",
    "    flat = fields.flatten()                    # shape: (N*7,)\n",
    "\n",
    "    return flat, N\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_yaw_case(base_dir, yaw_angle):\n",
    "    \"\"\"Load all snapshots for one yaw case, enforcing consistent shape.\"\"\"\n",
    "    X_list = []\n",
    "    yaw_list = []\n",
    "\n",
    "    time_dirs = sorted([d for d in os.listdir(base_dir) if d.isdigit()])\n",
    "\n",
    "    n_cells_ref = None\n",
    "\n",
    "    for t in time_dirs:\n",
    "        snapshot_dir = os.path.join(base_dir, t)\n",
    "        flat_vec, N = load_snapshot(snapshot_dir, n_cells_ref)\n",
    "\n",
    "        if n_cells_ref is None:\n",
    "            n_cells_ref = N  # first snapshot defines reference\n",
    "\n",
    "        X_list.append(flat_vec)\n",
    "        yaw_list.append(yaw_angle)\n",
    "\n",
    "    # Now everything should have identical length → safe to stack\n",
    "    X_arr = np.stack(X_list, axis=0)                 # shape: (num_times, D)\n",
    "    yaw_arr = np.array(yaw_list, dtype=float).reshape(-1, 1)  # shape: (num_times, 1)\n",
    "\n",
    "    return X_arr, yaw_arr, n_cells_ref\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Inconsistent cell count in ../0deg_baseline_csv/100: expected 1, but got 162506",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m folder, yaw_angle \u001b[38;5;129;01min\u001b[39;00m yaw_folders.items():\n\u001b[32m     15\u001b[39m     full_path = os.path.join(base_path, folder)\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m     Xi, yi, N = \u001b[43mload_yaw_case\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfull_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myaw_angle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfolder\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mXi.shape[\u001b[32m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m snapshots, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mN\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m cells per snapshot\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     20\u001b[39m     n_cells_each_case[yaw_angle] = N\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 12\u001b[39m, in \u001b[36mload_yaw_case\u001b[39m\u001b[34m(base_dir, yaw_angle)\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m time_dirs:\n\u001b[32m     11\u001b[39m     snapshot_dir = os.path.join(base_dir, t)\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m     flat_vec, N = \u001b[43mload_snapshot\u001b[49m\u001b[43m(\u001b[49m\u001b[43msnapshot_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_cells_ref\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n_cells_ref \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     15\u001b[39m         n_cells_ref = N  \u001b[38;5;66;03m# first snapshot defines reference\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 45\u001b[39m, in \u001b[36mload_snapshot\u001b[39m\u001b[34m(folder_path, n_cells_ref)\u001b[39m\n\u001b[32m     43\u001b[39m \u001b[38;5;66;03m# Optional: check against reference cell count from the first snapshot\u001b[39;00m\n\u001b[32m     44\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m n_cells_ref \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m N != n_cells_ref:\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m     46\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInconsistent cell count in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfolder_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     47\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mexpected \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_cells_ref\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mN\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     48\u001b[39m     )\n\u001b[32m     50\u001b[39m \u001b[38;5;66;03m# Concatenate along feature dimension and flatten\u001b[39;00m\n\u001b[32m     51\u001b[39m fields = np.hstack([U, p, k, nut, omega])  \u001b[38;5;66;03m# shape: (N, 7)\u001b[39;00m\n",
      "\u001b[31mValueError\u001b[39m: Inconsistent cell count in ../0deg_baseline_csv/100: expected 1, but got 162506"
     ]
    }
   ],
   "source": [
    "yaw_folders = {\n",
    "    \"0deg_baseline_csv\": 0.0,\n",
    "    \"15deg_baseline_csv\": 15.0,\n",
    "    \"30deg_baseline_csv\": 30.0,\n",
    "    \"45deg_baseline_csv\": 45.0,\n",
    "}\n",
    "\n",
    "X_all = []\n",
    "yaw_all = []\n",
    "n_cells_each_case = {}\n",
    "\n",
    "base_path = \"../\"  # adjust as needed\n",
    "\n",
    "for folder, yaw_angle in yaw_folders.items():\n",
    "    full_path = os.path.join(base_path, folder)\n",
    "    Xi, yi, N = load_yaw_case(full_path, yaw_angle)\n",
    "\n",
    "    print(f\"{folder}: {Xi.shape[0]} snapshots, {N} cells per snapshot\")\n",
    "\n",
    "    n_cells_each_case[yaw_angle] = N\n",
    "    X_all.append(Xi)\n",
    "    yaw_all.append(yi)\n",
    "\n",
    "X_all = np.vstack(X_all)\n",
    "yaw_all = np.vstack(yaw_all)\n",
    "\n",
    "print(\"Dataset shape:\", X_all.shape)\n",
    "print(\"Yaw labels shape:\", yaw_all.shape)\n",
    "print(\"Cells per case:\", n_cells_each_case)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "latent_dim = 50  # try 20–100\n",
    "\n",
    "pca = PCA(n_components=latent_dim)\n",
    "Z = pca.fit_transform(X_all)\n",
    "\n",
    "print(\"Latent Z shape:\", Z.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "class YawToLatent(nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(1, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, latent_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, yaw):\n",
    "        return self.net(yaw)\n",
    "\n",
    "\n",
    "model = YawToLatent(latent_dim)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "dataset = TensorDataset(torch.tensor(yaw_all, dtype=torch.float32),\n",
    "                        torch.tensor(Z, dtype=torch.float32))\n",
    "\n",
    "loader = DataLoader(dataset, batch_size=8, shuffle=True)\n",
    "\n",
    "for epoch in range(500):\n",
    "    for yaw_batch, z_batch in loader:\n",
    "        optimizer.zero_grad()\n",
    "        z_pred = model(yaw_batch)\n",
    "        loss = loss_fn(z_pred, z_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if epoch % 50 == 0:\n",
    "        print(\"Epoch\", epoch, \"loss\", loss.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yaw_query = torch.tensor([[22.5]], dtype=torch.float32)\n",
    "\n",
    "Z_pred = model(yaw_query).detach().numpy()\n",
    "X_pred = pca.inverse_transform(Z_pred)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = 3 + 1 + 1 + 1 + 1  # U + p + k + nut + omega\n",
    "N_cells = X_all.shape[1] // num_features\n",
    "\n",
    "pred_fields = X_pred.reshape(N_cells, num_features)\n",
    "\n",
    "Ux = pred_fields[:, 0]\n",
    "Uy = pred_fields[:, 1]\n",
    "Uz = pred_fields[:, 2]\n",
    "p  = pred_fields[:, 3]\n",
    "k  = pred_fields[:, 4]\n",
    "nut= pred_fields[:, 5]\n",
    "omega=pred_fields[:, 6]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
